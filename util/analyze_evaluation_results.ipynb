{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "03c59495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from meta_ally.eval.analyze_reports import (\n",
    "    load_evaluation_run,\n",
    "    reports_to_dataframe,\n",
    "    run_to_dataframe,\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ae343",
   "metadata": {},
   "source": [
    "## 1. Discover All Evaluation Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b3191291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 evaluation runs:\n",
      "\n",
      "  - multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_131941\n",
      "  - multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_135309\n",
      "  - multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_165341\n",
      "  - single_agent_improved_descriptions_gpt-4.1-mini_20260217_112944\n",
      "  - single_agent_improved_descriptions_gpt-4.1-mini_20260217_142937\n",
      "  - single_agent_improved_descriptions_gpt-4.1-mini_20260218_171249\n",
      "  - single_agent_improved_descriptions_gpt-5-mini_20260217_144852\n",
      "  - single_agent_improved_descriptions_gpt-5-mini_20260217_153733\n",
      "  - single_agent_improved_descriptions_gpt-5-mini_20260217_164843\n",
      "  - single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_100322\n",
      "  - single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_102954\n",
      "  - single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_173251\n"
     ]
    }
   ],
   "source": [
    "eval_base_dir = Path.cwd().parent / 'evaluation_results'\n",
    "\n",
    "run_dirs = sorted([d for d in eval_base_dir.iterdir() if d.is_dir()])\n",
    "print(f\"Found {len(run_dirs)} evaluation runs:\\n\")\n",
    "for run_dir in run_dirs:\n",
    "    print(f\"  - {run_dir.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e134c4",
   "metadata": {},
   "source": [
    "## 2. Load All Case Reports into DataFrames\n",
    "\n",
    "We'll create a function to load all reports from all folders and organize them by configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b5adc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 evaluation runs:\n",
      "\n",
      "multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_131941: 20 cases\n",
      "multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_135309: 24 cases\n",
      "multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_165341: 19 cases\n",
      "single_agent_improved_descriptions_gpt-4.1-mini_20260217_112944: 24 cases\n",
      "single_agent_improved_descriptions_gpt-4.1-mini_20260217_142937: 20 cases\n",
      "single_agent_improved_descriptions_gpt-4.1-mini_20260218_171249: 19 cases\n",
      "single_agent_improved_descriptions_gpt-5-mini_20260217_144852: 20 cases\n",
      "single_agent_improved_descriptions_gpt-5-mini_20260217_153733: 24 cases\n",
      "single_agent_improved_descriptions_gpt-5-mini_20260217_164843: 19 cases\n",
      "single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_100322: 24 cases\n",
      "single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_102954: 20 cases\n",
      "single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_173251: 19 cases\n"
     ]
    }
   ],
   "source": [
    "def load_all_case_reports(base_dir: Path) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load all case reports from all evaluation runs.\n",
    "    \n",
    "    Returns a dictionary where keys are folder names and values are DataFrames\n",
    "    containing all cases from all reports in that folder.\n",
    "    \"\"\"\n",
    "    all_reports = {}\n",
    "    \n",
    "    for run_dir in sorted([d for d in base_dir.iterdir() if d.is_dir()]):\n",
    "        reports_dir = run_dir / 'reports'\n",
    "        if not reports_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # Load all case JSON files in the reports directory\n",
    "        case_files = sorted(reports_dir.glob('*.json'))\n",
    "        \n",
    "        all_cases = []\n",
    "        for case_file in case_files:\n",
    "            with open(case_file, 'r', encoding='utf-8') as f:\n",
    "                report = json.load(f)\n",
    "                \n",
    "            # Extract case name from filename\n",
    "            dataset_id = case_file.stem\n",
    "            \n",
    "            # Process each case in the report\n",
    "            for case in report.get('cases', []):\n",
    "                case_dict = {\n",
    "                    'run_folder': run_dir.name,\n",
    "                    'dataset_id': dataset_id,\n",
    "                    'case_name': case['name'],\n",
    "                }\n",
    "                \n",
    "                # Add metrics (with 0.5 multiplier to fix doubled counts)\n",
    "                metrics = case.get('metrics', {})\n",
    "                case_dict['input_tokens'] = metrics.get('input_tokens', 0) * 0.5\n",
    "                case_dict['output_tokens'] = metrics.get('output_tokens', 0) * 0.5\n",
    "                case_dict['requests'] = metrics.get('requests', 0)\n",
    "                case_dict['cost'] = metrics.get('cost', 0.0)\n",
    "                \n",
    "                # Add scores\n",
    "                scores = case.get('scores', {})\n",
    "                for score_name, score_data in scores.items():\n",
    "                    col_name = score_name.replace(' ', '_').replace('-', '_')\n",
    "                    case_dict[f'score_{col_name}'] = score_data.get('value', 0.0)\n",
    "                    case_dict[f'score_{col_name}_reason'] = score_data.get('reason', None)\n",
    "                \n",
    "                # Add assertions\n",
    "                assertions = case.get('assertions', {})\n",
    "                for assertion_name, assertion_data in assertions.items():\n",
    "                    col_name = assertion_name.replace(' ', '_').replace('-', '_')\n",
    "                    case_dict[f'assertion_{col_name}'] = assertion_data.get('value', None)\n",
    "                \n",
    "                all_cases.append(case_dict)\n",
    "        \n",
    "        if all_cases:\n",
    "            all_reports[run_dir.name] = pd.DataFrame(all_cases)\n",
    "    \n",
    "    return all_reports\n",
    "\n",
    "# Load all reports\n",
    "all_case_dfs = load_all_case_reports(eval_base_dir)\n",
    "\n",
    "print(f\"Loaded {len(all_case_dfs)} evaluation runs:\\n\")\n",
    "for folder_name, df in all_case_dfs.items():\n",
    "    print(f\"{folder_name}: {len(df)} cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea23ff",
   "metadata": {},
   "source": [
    "## 3. Create Combined DataFrame\n",
    "\n",
    "Combine all runs into a single DataFrame for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "03092c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (252, 15)\n",
      "\n",
      "Columns: ['run_folder', 'dataset_id', 'case_name', 'input_tokens', 'output_tokens', 'requests', 'cost', 'score_ToolCallEvaluator', 'score_ToolCallEvaluator_reason', 'score_Helpfulness_and_accuracy', 'score_Helpfulness_and_accuracy_reason', 'score_Tool_Call_Evaluation', 'score_Tool_Call_Evaluation_reason', 'assertion_LLMJudge_pass', 'assertion_LLMJudge_pass_2']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_folder</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>case_name</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>requests</th>\n",
       "      <th>cost</th>\n",
       "      <th>score_ToolCallEvaluator</th>\n",
       "      <th>score_ToolCallEvaluator_reason</th>\n",
       "      <th>score_Helpfulness_and_accuracy</th>\n",
       "      <th>score_Helpfulness_and_accuracy_reason</th>\n",
       "      <th>score_Tool_Call_Evaluation</th>\n",
       "      <th>score_Tool_Call_Evaluation_reason</th>\n",
       "      <th>assertion_LLMJudge_pass</th>\n",
       "      <th>assertion_LLMJudge_pass_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage</td>\n",
       "      <td>190918.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.077417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model's last response provides a clear, ac...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage -...</td>\n",
       "      <td>3904.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage -...</td>\n",
       "      <td>184134.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.074236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified that no Copilot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage -...</td>\n",
       "      <td>286270.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.115673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model's last response provides a detailed ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_2</td>\n",
       "      <td>INFORM Webseite Analytics - Vollst채ndige Analy...</td>\n",
       "      <td>60698.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model's final response provides a clear, a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the business ar...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_folder        dataset_id  \\\n",
       "0  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "1  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "2  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "3  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "4  multi_agent_orchestrator_improved_descriptions...  analytics_case_2   \n",
       "\n",
       "                                           case_name  input_tokens  \\\n",
       "0       INFORM Webseite Analytics - Initiale Anfrage      190918.0   \n",
       "1  INFORM Webseite Analytics - Initiale Anfrage -...        3904.0   \n",
       "2  INFORM Webseite Analytics - Initiale Anfrage -...      184134.0   \n",
       "3  INFORM Webseite Analytics - Initiale Anfrage -...      286270.0   \n",
       "4  INFORM Webseite Analytics - Vollst채ndige Analy...       60698.0   \n",
       "\n",
       "   output_tokens  requests      cost  score_ToolCallEvaluator  \\\n",
       "0          656.0         8  0.077417                      0.0   \n",
       "1           85.0         2  0.001698                      0.0   \n",
       "2          364.0         7  0.074236                      0.0   \n",
       "3          728.0        10  0.115673                      0.0   \n",
       "4          545.0         4  0.025151                      0.0   \n",
       "\n",
       "  score_ToolCallEvaluator_reason  score_Helpfulness_and_accuracy  \\\n",
       "0                           None                             1.0   \n",
       "1                           None                             1.0   \n",
       "2                           None                             1.0   \n",
       "3                           None                             1.0   \n",
       "4                           None                             1.0   \n",
       "\n",
       "               score_Helpfulness_and_accuracy_reason  \\\n",
       "0  The model's last response provides a clear, ac...   \n",
       "1  The model correctly identified the user's busi...   \n",
       "2  The model correctly identified that no Copilot...   \n",
       "3  The model's last response provides a detailed ...   \n",
       "4  The model's final response provides a clear, a...   \n",
       "\n",
       "   score_Tool_Call_Evaluation  \\\n",
       "0                         1.0   \n",
       "1                         1.0   \n",
       "2                         1.0   \n",
       "3                         1.0   \n",
       "4                         1.0   \n",
       "\n",
       "                   score_Tool_Call_Evaluation_reason  assertion_LLMJudge_pass  \\\n",
       "0  The model correctly identified the user's busi...                     True   \n",
       "1  The model correctly identified the user's busi...                     True   \n",
       "2  The model correctly identified the user's busi...                     True   \n",
       "3  The model correctly identified the user's busi...                     True   \n",
       "4  The model correctly identified the business ar...                     True   \n",
       "\n",
       "   assertion_LLMJudge_pass_2  \n",
       "0                       True  \n",
       "1                       True  \n",
       "2                       True  \n",
       "3                       True  \n",
       "4                       True  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat(all_case_dfs.values(), ignore_index=True)\n",
    "\n",
    "print(f\"Combined DataFrame shape: {combined_df.shape}\")\n",
    "print(f\"\\nColumns: {list(combined_df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35927b4",
   "metadata": {},
   "source": [
    "## 4. Parse Configuration Information\n",
    "\n",
    "Extract agent type, model, and improved descriptions flag from folder names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eb8fae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration distribution:\n",
      "agent_type    model         improved_descriptions\n",
      "multi_agent   gpt-4.1-mini  True                     63\n",
      "single_agent  gpt-4.1-mini  False                    63\n",
      "                            True                     63\n",
      "              gpt-5-mini    True                     63\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Hardcoded configuration mapping\n",
    "FOLDER_CONFIGS = {\n",
    "    'single_agent_improved_descriptions_gpt-5-mini_20260217_144852': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-5-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'single_agent_improved_descriptions_gpt-5-mini_20260217_153733': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-5-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'single_agent_improved_descriptions_gpt-5-mini_20260217_164843': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-5-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_173251': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': False\n",
    "    },\n",
    "    'single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_100322': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': False\n",
    "    },\n",
    "    'single_agent_no_improved_descriptions_gpt-4.1-mini_20260218_102954': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': False\n",
    "    },\n",
    "    'single_agent_improved_descriptions_gpt-4.1-mini_20260217_112944': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'single_agent_improved_descriptions_gpt-4.1-mini_20260217_142937': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'single_agent_improved_descriptions_gpt-4.1-mini_20260218_171249': {\n",
    "        'agent_type': 'single_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_131941': {\n",
    "        'agent_type': 'multi_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_135309': {\n",
    "        'agent_type': 'multi_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': True\n",
    "    },\n",
    "    'multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_165341': {\n",
    "        'agent_type': 'multi_agent',\n",
    "        'model': 'gpt-4.1-mini',\n",
    "        'improved_descriptions': True\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_config_from_folder(folder_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get configuration info from hardcoded mapping.\n",
    "    \n",
    "    Returns: {'agent_type': str, 'improved_descriptions': bool, 'model': str}\n",
    "    \"\"\"\n",
    "    return FOLDER_CONFIGS.get(folder_name, {\n",
    "        'agent_type': 'unknown',\n",
    "        'improved_descriptions': False,\n",
    "        'model': 'unknown'\n",
    "    })\n",
    "\n",
    "# Add configuration columns\n",
    "config_info = combined_df['run_folder'].apply(get_config_from_folder)\n",
    "combined_df['agent_type'] = config_info.apply(lambda x: x['agent_type'])\n",
    "combined_df['improved_descriptions'] = config_info.apply(lambda x: x['improved_descriptions'])\n",
    "combined_df['model'] = config_info.apply(lambda x: x['model'])\n",
    "\n",
    "print(\"Configuration distribution:\")\n",
    "print(combined_df.groupby(['agent_type', 'model', 'improved_descriptions']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc6834",
   "metadata": {},
   "source": [
    "## 5. Parse Dataset Type\n",
    "\n",
    "Extract dataset type (addone, analytics, testing_and_access) from dataset_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8691076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type distribution:\n",
      "dataset_type\n",
      "addone                96\n",
      "analytics             80\n",
      "testing_and_access    76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def parse_dataset_type(dataset_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract dataset type from dataset_id.\n",
    "    \n",
    "    Example: 'addone_case_1' -> 'addone'\n",
    "             'analytics_case_2' -> 'analytics'\n",
    "    \"\"\"\n",
    "    if dataset_id.startswith('addone'):\n",
    "        return 'addone'\n",
    "    elif dataset_id.startswith('analytics'):\n",
    "        return 'analytics'\n",
    "    elif dataset_id.startswith('testing') or dataset_id.startswith('access'):\n",
    "        return 'testing_and_access'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "combined_df['dataset_type'] = combined_df['dataset_id'].apply(parse_dataset_type)\n",
    "\n",
    "print(\"Dataset type distribution:\")\n",
    "print(combined_df['dataset_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c985c7",
   "metadata": {},
   "source": [
    "## 6. Individual DataFrames by Configuration\n",
    "\n",
    "Access individual DataFrames by folder name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b2908574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: multi_agent_orchestrator_improved_descriptions_gpt-4.1-mini_20260218_131941\n",
      "Shape: (20, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_folder</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>case_name</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>requests</th>\n",
       "      <th>cost</th>\n",
       "      <th>score_ToolCallEvaluator</th>\n",
       "      <th>score_ToolCallEvaluator_reason</th>\n",
       "      <th>score_Helpfulness_and_accuracy</th>\n",
       "      <th>score_Helpfulness_and_accuracy_reason</th>\n",
       "      <th>score_Tool_Call_Evaluation</th>\n",
       "      <th>score_Tool_Call_Evaluation_reason</th>\n",
       "      <th>assertion_LLMJudge_pass</th>\n",
       "      <th>assertion_LLMJudge_pass_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage</td>\n",
       "      <td>190918.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.077417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model's last response provides a clear, ac...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage -...</td>\n",
       "      <td>3904.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage -...</td>\n",
       "      <td>184134.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.074236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified that no Copilot...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_1</td>\n",
       "      <td>INFORM Webseite Analytics - Initiale Anfrage -...</td>\n",
       "      <td>286270.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.115673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model's last response provides a detailed ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the user's busi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multi_agent_orchestrator_improved_descriptions...</td>\n",
       "      <td>analytics_case_2</td>\n",
       "      <td>INFORM Webseite Analytics - Vollst채ndige Analy...</td>\n",
       "      <td>60698.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model's final response provides a clear, a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The model correctly identified the business ar...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_folder        dataset_id  \\\n",
       "0  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "1  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "2  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "3  multi_agent_orchestrator_improved_descriptions...  analytics_case_1   \n",
       "4  multi_agent_orchestrator_improved_descriptions...  analytics_case_2   \n",
       "\n",
       "                                           case_name  input_tokens  \\\n",
       "0       INFORM Webseite Analytics - Initiale Anfrage      190918.0   \n",
       "1  INFORM Webseite Analytics - Initiale Anfrage -...        3904.0   \n",
       "2  INFORM Webseite Analytics - Initiale Anfrage -...      184134.0   \n",
       "3  INFORM Webseite Analytics - Initiale Anfrage -...      286270.0   \n",
       "4  INFORM Webseite Analytics - Vollst채ndige Analy...       60698.0   \n",
       "\n",
       "   output_tokens  requests      cost  score_ToolCallEvaluator  \\\n",
       "0          656.0         8  0.077417                      0.0   \n",
       "1           85.0         2  0.001698                      0.0   \n",
       "2          364.0         7  0.074236                      0.0   \n",
       "3          728.0        10  0.115673                      0.0   \n",
       "4          545.0         4  0.025151                      0.0   \n",
       "\n",
       "  score_ToolCallEvaluator_reason  score_Helpfulness_and_accuracy  \\\n",
       "0                           None                             1.0   \n",
       "1                           None                             1.0   \n",
       "2                           None                             1.0   \n",
       "3                           None                             1.0   \n",
       "4                           None                             1.0   \n",
       "\n",
       "               score_Helpfulness_and_accuracy_reason  \\\n",
       "0  The model's last response provides a clear, ac...   \n",
       "1  The model correctly identified the user's busi...   \n",
       "2  The model correctly identified that no Copilot...   \n",
       "3  The model's last response provides a detailed ...   \n",
       "4  The model's final response provides a clear, a...   \n",
       "\n",
       "   score_Tool_Call_Evaluation  \\\n",
       "0                         1.0   \n",
       "1                         1.0   \n",
       "2                         1.0   \n",
       "3                         1.0   \n",
       "4                         1.0   \n",
       "\n",
       "                   score_Tool_Call_Evaluation_reason  assertion_LLMJudge_pass  \\\n",
       "0  The model correctly identified the user's busi...                     True   \n",
       "1  The model correctly identified the user's busi...                     True   \n",
       "2  The model correctly identified the user's busi...                     True   \n",
       "3  The model correctly identified the user's busi...                     True   \n",
       "4  The model correctly identified the business ar...                     True   \n",
       "\n",
       "   assertion_LLMJudge_pass_2  \n",
       "0                       True  \n",
       "1                       True  \n",
       "2                       True  \n",
       "3                       True  \n",
       "4                       True  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Get one specific run\n",
    "example_folder = list(all_case_dfs.keys())[0]\n",
    "example_df = all_case_dfs[example_folder]\n",
    "\n",
    "print(f\"Example: {example_folder}\")\n",
    "print(f\"Shape: {example_df.shape}\")\n",
    "example_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f94c7d",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics\n",
    "\n",
    "Calculate summary statistics across configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1785e504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "      <th>Avg. In. Tok.</th>\n",
       "      <th>Avg. Out. Tok.</th>\n",
       "      <th>Avg. Cost</th>\n",
       "      <th>Tool Names</th>\n",
       "      <th>Helpfulness And Accuracy</th>\n",
       "      <th>Tool Call Evaluation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agent Type</th>\n",
       "      <th>Model</th>\n",
       "      <th>Improved Descriptions</th>\n",
       "      <th>User Story</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Multi</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">gpt-4.1-mini</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>AddOne</th>\n",
       "      <td>24</td>\n",
       "      <td>21154.42</td>\n",
       "      <td>294.96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytics</th>\n",
       "      <td>20</td>\n",
       "      <td>62307.50</td>\n",
       "      <td>541.60</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing and Access</th>\n",
       "      <td>19</td>\n",
       "      <td>26000.47</td>\n",
       "      <td>364.68</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">Single</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">gpt-4.1-mini</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">False</th>\n",
       "      <th>AddOne</th>\n",
       "      <td>24</td>\n",
       "      <td>61426.79</td>\n",
       "      <td>203.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytics</th>\n",
       "      <td>20</td>\n",
       "      <td>55883.05</td>\n",
       "      <td>227.85</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing and Access</th>\n",
       "      <td>19</td>\n",
       "      <td>61817.84</td>\n",
       "      <td>110.95</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>AddOne</th>\n",
       "      <td>24</td>\n",
       "      <td>47465.17</td>\n",
       "      <td>215.29</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytics</th>\n",
       "      <td>20</td>\n",
       "      <td>48653.20</td>\n",
       "      <td>242.35</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing and Access</th>\n",
       "      <td>19</td>\n",
       "      <td>64103.16</td>\n",
       "      <td>116.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">gpt-5-mini</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>AddOne</th>\n",
       "      <td>24</td>\n",
       "      <td>94873.08</td>\n",
       "      <td>2233.88</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analytics</th>\n",
       "      <td>20</td>\n",
       "      <td>99826.05</td>\n",
       "      <td>3685.90</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing and Access</th>\n",
       "      <td>19</td>\n",
       "      <td>106820.42</td>\n",
       "      <td>1856.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Cases  \\\n",
       "Agent Type Model        Improved Descriptions User Story                  \n",
       "Multi      gpt-4.1-mini True                  AddOne                 24   \n",
       "                                              Analytics              20   \n",
       "                                              Testing and Access     19   \n",
       "Single     gpt-4.1-mini False                 AddOne                 24   \n",
       "                                              Analytics              20   \n",
       "                                              Testing and Access     19   \n",
       "                        True                  AddOne                 24   \n",
       "                                              Analytics              20   \n",
       "                                              Testing and Access     19   \n",
       "           gpt-5-mini   True                  AddOne                 24   \n",
       "                                              Analytics              20   \n",
       "                                              Testing and Access     19   \n",
       "\n",
       "                                                                  Avg. In. Tok.  \\\n",
       "Agent Type Model        Improved Descriptions User Story                          \n",
       "Multi      gpt-4.1-mini True                  AddOne                   21154.42   \n",
       "                                              Analytics                62307.50   \n",
       "                                              Testing and Access       26000.47   \n",
       "Single     gpt-4.1-mini False                 AddOne                   61426.79   \n",
       "                                              Analytics                55883.05   \n",
       "                                              Testing and Access       61817.84   \n",
       "                        True                  AddOne                   47465.17   \n",
       "                                              Analytics                48653.20   \n",
       "                                              Testing and Access       64103.16   \n",
       "           gpt-5-mini   True                  AddOne                   94873.08   \n",
       "                                              Analytics                99826.05   \n",
       "                                              Testing and Access      106820.42   \n",
       "\n",
       "                                                                  Avg. Out. Tok.  \\\n",
       "Agent Type Model        Improved Descriptions User Story                           \n",
       "Multi      gpt-4.1-mini True                  AddOne                      294.96   \n",
       "                                              Analytics                   541.60   \n",
       "                                              Testing and Access          364.68   \n",
       "Single     gpt-4.1-mini False                 AddOne                      203.33   \n",
       "                                              Analytics                   227.85   \n",
       "                                              Testing and Access          110.95   \n",
       "                        True                  AddOne                      215.29   \n",
       "                                              Analytics                   242.35   \n",
       "                                              Testing and Access          116.11   \n",
       "           gpt-5-mini   True                  AddOne                     2233.88   \n",
       "                                              Analytics                  3685.90   \n",
       "                                              Testing and Access         1856.74   \n",
       "\n",
       "                                                                  Avg. Cost  \\\n",
       "Agent Type Model        Improved Descriptions User Story                      \n",
       "Multi      gpt-4.1-mini True                  AddOne                   0.01   \n",
       "                                              Analytics                0.03   \n",
       "                                              Testing and Access       0.01   \n",
       "Single     gpt-4.1-mini False                 AddOne                   0.02   \n",
       "                                              Analytics                0.02   \n",
       "                                              Testing and Access       0.02   \n",
       "                        True                  AddOne                   0.02   \n",
       "                                              Analytics                0.02   \n",
       "                                              Testing and Access       0.03   \n",
       "           gpt-5-mini   True                  AddOne                   0.03   \n",
       "                                              Analytics                0.03   \n",
       "                                              Testing and Access       0.03   \n",
       "\n",
       "                                                                  Tool Names  \\\n",
       "Agent Type Model        Improved Descriptions User Story                       \n",
       "Multi      gpt-4.1-mini True                  AddOne                    0.62   \n",
       "                                              Analytics                 0.10   \n",
       "                                              Testing and Access        0.46   \n",
       "Single     gpt-4.1-mini False                 AddOne                    0.80   \n",
       "                                              Analytics                 0.39   \n",
       "                                              Testing and Access        0.61   \n",
       "                        True                  AddOne                    0.63   \n",
       "                                              Analytics                 0.45   \n",
       "                                              Testing and Access        0.58   \n",
       "           gpt-5-mini   True                  AddOne                    0.71   \n",
       "                                              Analytics                 0.25   \n",
       "                                              Testing and Access        0.67   \n",
       "\n",
       "                                                                  Helpfulness And Accuracy  \\\n",
       "Agent Type Model        Improved Descriptions User Story                                     \n",
       "Multi      gpt-4.1-mini True                  AddOne                                  0.99   \n",
       "                                              Analytics                               0.93   \n",
       "                                              Testing and Access                      0.96   \n",
       "Single     gpt-4.1-mini False                 AddOne                                  0.96   \n",
       "                                              Analytics                               0.96   \n",
       "                                              Testing and Access                      0.78   \n",
       "                        True                  AddOne                                  0.96   \n",
       "                                              Analytics                               0.97   \n",
       "                                              Testing and Access                      0.79   \n",
       "           gpt-5-mini   True                  AddOne                                  0.96   \n",
       "                                              Analytics                               0.99   \n",
       "                                              Testing and Access                      0.99   \n",
       "\n",
       "                                                                  Tool Call Evaluation  \n",
       "Agent Type Model        Improved Descriptions User Story                                \n",
       "Multi      gpt-4.1-mini True                  AddOne                              0.96  \n",
       "                                              Analytics                           0.82  \n",
       "                                              Testing and Access                  1.00  \n",
       "Single     gpt-4.1-mini False                 AddOne                              0.92  \n",
       "                                              Analytics                           0.74  \n",
       "                                              Testing and Access                  0.78  \n",
       "                        True                  AddOne                              0.92  \n",
       "                                              Analytics                           0.74  \n",
       "                                              Testing and Access                  0.76  \n",
       "           gpt-5-mini   True                  AddOne                              0.92  \n",
       "                                              Analytics                           0.84  \n",
       "                                              Testing and Access                  0.94  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score columns\n",
    "score_cols = [col for col in combined_df.columns if col.startswith('score_') and not col.endswith('_reason')]\n",
    "\n",
    "# Create a copy and rename values for cleaner display\n",
    "df_for_summary = combined_df.copy()\n",
    "df_for_summary['agent_type'] = df_for_summary['agent_type'].replace({\n",
    "    'multi_agent': 'Multi',\n",
    "    'single_agent': 'Single'\n",
    "})\n",
    "df_for_summary['dataset_type'] = df_for_summary['dataset_type'].replace({\n",
    "    'addone': 'AddOne',\n",
    "    'analytics': 'Analytics',\n",
    "    'testing_and_access': 'Testing and Access'\n",
    "})\n",
    "\n",
    "# Summary by configuration (rename dataset_type to User Story in groupby)\n",
    "summary = df_for_summary.rename(columns={'dataset_type': 'User Story'}).groupby(['agent_type', 'model', 'improved_descriptions', 'User Story']).agg({\n",
    "    'case_name': 'count',\n",
    "    'input_tokens': 'mean',\n",
    "    'output_tokens': 'mean',\n",
    "    'cost': 'mean',\n",
    "    **{col: 'mean' for col in score_cols}\n",
    "}).round(2)\n",
    "\n",
    "# Rename columns to abbreviated report-style names\n",
    "column_renames = {\n",
    "    'case_name': 'Cases',\n",
    "    'input_tokens': 'Avg. In. Tok.',\n",
    "    'output_tokens': 'Avg. Out. Tok.',\n",
    "    'cost': 'Avg. Cost'\n",
    "}\n",
    "\n",
    "# Add shortened score column names (remove 'score_' prefix)\n",
    "for col in score_cols:\n",
    "    # Convert score_some_name -> Some Name\n",
    "    clean_name = col.replace('score_', '').replace('_', ' ').title()\n",
    "    # Special case for Toolcallevaluator\n",
    "    if clean_name == 'Toolcallevaluator':\n",
    "        clean_name = 'Tool Names'\n",
    "    column_renames[col] = clean_name\n",
    "\n",
    "summary.rename(columns=column_renames, inplace=True)\n",
    "\n",
    "# Rename index levels for cleaner display\n",
    "\n",
    "summary.index.names = ['Agent Type', 'Model', 'Improved Descriptions', 'User Story']\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ee09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Evaluation Summary by Configuration and User Story}\n",
      "\\label{tab:eval_summary}\n",
      "\\begin{tabular}{llllrrrrrrr}\n",
      "\\toprule\n",
      " &  &  &  & Cases & \\makecell[t]{Avg.\\\\In. Tok.} & \\makecell[t]{Avg.\\\\Out. Tok.} & \\makecell[t]{Avg.\\\\Cost} & \\makecell[t]{Tool\\\\Names} & \\makecell[t]{Helpfulness\\\\And Accuracy} & \\makecell[t]{Tool\\\\Call Evaluation} \\\\\n",
      "\\makecell[t]{Agent\\\\Type} & Model & \\makecell[t]{Improved\\\\Descriptions} & \\makecell[t]{User\\\\Story} &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{3}{*}{Multi} & \\multirow[t]{3}{*}{\\makecell[t]{gpt-\\\\4.1-mini}} & \\multirow[t]{3}{*}{True} & AddOne & 24 & 21154.42 & 294.96 & 0.01 & 0.62 & 0.99 & 0.96 \\\\\n",
      " &  &  & Analytics & 20 & 62307.50 & 541.60 & 0.03 & 0.10 & 0.93 & 0.82 \\\\\n",
      " &  &  & \\makecell[t]{Testing\\\\and Access} & 19 & 26000.47 & 364.68 & 0.01 & 0.46 & 0.96 & 1.00 \\\\\n",
      "\\cline{1-11} \\cline{2-11} \\cline{3-11}\n",
      "\\multirow[t]{9}{*}{Single} & \\multirow[t]{6}{*}{\\makecell[t]{gpt-\\\\4.1-mini}} & \\multirow[t]{3}{*}{False} & AddOne & 24 & 61426.79 & 203.33 & 0.02 & 0.80 & 0.96 & 0.92 \\\\\n",
      " &  &  & Analytics & 20 & 55883.05 & 227.85 & 0.02 & 0.39 & 0.96 & 0.74 \\\\\n",
      " &  &  & \\makecell[t]{Testing\\\\and Access} & 19 & 61817.84 & 110.95 & 0.02 & 0.61 & 0.78 & 0.78 \\\\\n",
      "\\cline{3-11}\n",
      " &  & \\multirow[t]{3}{*}{True} & AddOne & 24 & 47465.17 & 215.29 & 0.02 & 0.63 & 0.96 & 0.92 \\\\\n",
      " &  &  & Analytics & 20 & 48653.20 & 242.35 & 0.02 & 0.45 & 0.97 & 0.74 \\\\\n",
      " &  &  & \\makecell[t]{Testing\\\\and Access} & 19 & 64103.16 & 116.11 & 0.03 & 0.58 & 0.79 & 0.76 \\\\\n",
      "\\cline{2-11} \\cline{3-11}\n",
      " & \\multirow[t]{3}{*}{gpt-5-mini} & \\multirow[t]{3}{*}{True} & AddOne & 24 & 94873.08 & 2233.88 & 0.03 & 0.71 & 0.96 & 0.92 \\\\\n",
      " &  &  & Analytics & 20 & 99826.05 & 3685.90 & 0.03 & 0.25 & 0.99 & 0.84 \\\\\n",
      " &  &  & \\makecell[t]{Testing\\\\and Access} & 19 & 106820.42 & 1856.74 & 0.03 & 0.67 & 0.99 & 0.94 \\\\\n",
      "\\cline{1-11} \\cline{2-11} \\cline{3-11}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert summary to LaTeX table with line breaks in column names, index names, and values\n",
    "summary_latex = summary.copy()\n",
    "\n",
    "# Helper function to add line breaks using makecell with alignment\n",
    "def add_line_breaks(text, min_length=5):\n",
    "    \"\"\"Add line breaks to text longer than min_length\"\"\"\n",
    "    if len(text) <= min_length:\n",
    "        return text\n",
    "    \n",
    "    # Special handling for model names with hyphens (split after hyphen)\n",
    "    if '-' in text and '.' in text:  # Likely a model name like gpt-4.1-mini\n",
    "        parts = text.split('-', 1)  # Split on first hyphen\n",
    "        if len(parts) == 2:\n",
    "            return f\"\\\\makecell[tl]{{{parts[0]}-\\\\\\\\{parts[1]}}}\"\n",
    "    \n",
    "    # Split at spaces\n",
    "    words = text.split()\n",
    "    if len(words) > 1:\n",
    "        mid = len(words) // 2\n",
    "        line1 = ' '.join(words[:mid])\n",
    "        line2 = ' '.join(words[mid:])\n",
    "        return f\"\\\\makecell[tl]{{{line1}\\\\\\\\{line2}}}\"\n",
    "    return text\n",
    "\n",
    "# Apply line breaks to User Story and Model values in the index FIRST (before changing index names)\n",
    "# Reset index to modify, then set it back\n",
    "summary_latex = summary_latex.reset_index()\n",
    "summary_latex['User Story'] = summary_latex['User Story'].apply(lambda x: add_line_breaks(x) if isinstance(x, str) else x)\n",
    "summary_latex['Model'] = summary_latex['Model'].apply(lambda x: add_line_breaks(x) if isinstance(x, str) else x)\n",
    "summary_latex = summary_latex.set_index(['Agent Type', 'Model', 'Improved Descriptions', 'User Story'])\n",
    "\n",
    "# Now apply line breaks to column names\n",
    "summary_latex.columns = [add_line_breaks(col) for col in summary_latex.columns]\n",
    "\n",
    "# Apply line breaks to index level names (after setting the index)\n",
    "summary_latex.index.names = [add_line_breaks(name) if name else name for name in summary_latex.index.names]\n",
    "\n",
    "latex_table = summary_latex.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    caption=\"Evaluation Summary by Configuration and User Story\",\n",
    "    label=\"tab:eval_summary\",\n",
    "    escape=False,  # Don't escape because we're adding LaTeX commands\n",
    "    multirow=True,\n",
    "    multicolumn=True\n",
    ")\n",
    "\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e4805",
   "metadata": {},
   "source": [
    "## 8. Export Options\n",
    "\n",
    "Save DataFrames for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cde38376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To export, uncomment the desired lines above.\n"
     ]
    }
   ],
   "source": [
    "# Export combined dataframe\n",
    "# combined_df.to_csv('combined_evaluation_results.csv', index=False)\n",
    "\n",
    "# Export summary\n",
    "# summary.to_csv('evaluation_summary.csv')\n",
    "\n",
    "# Export individual run dataframes\n",
    "# for folder_name, df in all_case_dfs.items():\n",
    "#     df.to_csv(f'{folder_name}.csv', index=False)\n",
    "\n",
    "print(\"To export, uncomment the desired lines above.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-ally",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
